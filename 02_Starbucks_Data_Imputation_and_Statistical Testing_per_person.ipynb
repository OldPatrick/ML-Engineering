{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Complete.use_jedi = False\n",
    "#!pip install datatable\n",
    "#!pip install mlxtend\n",
    "#http://rasbt.github.io/mlxtend/user_guide/evaluate/permutation_test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import datatable as dt\n",
    "from mlxtend.evaluate import permutation_test\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "starbucks = dt.fread(\"./starbucks_data/starbucks_df_per_person.csv\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 rows are missing in the duration thingy, we will drop these, they should not have that h impact\n",
    "starbucks = starbucks[starbucks.difficulty_offered.notna() & starbucks.duration_offered.notna()]\n",
    "starbucks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need that later for mapping\n",
    "starbucks.to_csv(\"./starbucks_data/starbucks_df_per_id.csv\", index=False)\n",
    "starbucks.drop(columns=[\"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks.gender.unique()\n",
    "# the empty gender rows may be equal to the missing income rows, we will check that later before the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(starbucks, x=\"gender\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(starbucks, x=\"income\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_filtered=starbucks[starbucks.gender.notna()]\n",
    "fig = px.histogram(starbucks_filtered, x=\"income\", color=starbucks_filtered.gender, marginal=\"violin\",\n",
    "                         hover_data=starbucks.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interestingly we see for our data without missing values that we have mor male consumer with less income (right_skewed toward male)\n",
    "#while the distribution of female and Other seems normally distributed the male's distribution is not\n",
    "#epecially male with higher income (right side of distribution) do not tend to be in the data so often \n",
    "print(starbucks_filtered[(starbucks_filtered.gender ==\"M\") & (starbucks_filtered.income > 100000)].count().max())\n",
    "print(starbucks_filtered[(starbucks_filtered.gender ==\"F\") & (starbucks_filtered.income > 100000)].count().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing will be done with ExtraTrees since it is as stable as RandoMForest but much faster and without AWS\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "#no need for train test split, since we will split it with NaNs\n",
    "\n",
    "# the question is which value we should impute first, so does income prediction benefits from having the gender first or vice versa?\n",
    "# we do not know if the people who has not answered the income question are also Male, which could lift the distribution to a normally state for example, and without having the income\n",
    "# the problem is, that these variables are henne-ei problem, because salary sometimes underlies a gender-pay-gap unfortunately, so \n",
    "#the gender would have been the ideal variable to forecast income and vice versa\n",
    "\n",
    "#however I believe that forecasting income first would be more reliable since ppl with less income would probably receive specific rewards, \n",
    "#they do not have the money to buy so often, thus they probably get more bogo offers\n",
    "#thus forecasting income with the coupons could be more effective without distorting the forecast of income when having the gender\n",
    "#lets check that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_filtered=starbucks[starbucks.gender.notna()]\n",
    "fig = px.histogram(starbucks_filtered, x=\"income\", y=starbucks_filtered.total_reward_completed, color=starbucks_filtered.gender, marginal=\"violin\",\n",
    "                         hover_data=starbucks.columns)\n",
    "fig.show()\n",
    "#since we counted the bogo offers per person several bogos per person may appear, interestingly \n",
    "# the bogo offers show what we expected , but it also looks like the MAle distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why do we look at the median for this? Well splitting income into two halves may be useful, \n",
    "#e.g. uci income data also makes a label for above or below 50k (source)\n",
    "print(np.median(starbucks_filtered.income.fillna(0)))\n",
    "print(np.mean(starbucks_filtered.income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#however the median seems not to help, it seems that they also get less bogo, probably they cant afford to buy one so often, that they should not get the next one for free,\n",
    "#the strcuture is that low income people get more informational and less value rewarindg coupons, but it seems not significant ()\n",
    "print(\"bogo high:\", starbucks_filtered.bogo[starbucks_filtered.income > 59000.0].sum())\n",
    "print(\"bogo low:\", starbucks_filtered.bogo[starbucks_filtered.income <= 59000.0].sum())\n",
    "print(\"discount high:\", starbucks_filtered.discount[starbucks_filtered.income > 59000.0].sum())\n",
    "print(\"discount low:\", starbucks_filtered.discount[starbucks_filtered.income <= 59000.0].sum())\n",
    "print(\"informational high:\", starbucks_filtered.informational[starbucks_filtered.income > 59000.0].sum())\n",
    "print(\"informational low:\", starbucks_filtered.informational[starbucks_filtered.income <= 59000.0].sum())\n",
    "\n",
    "#permutation test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#however the mean seems not to help, it seems that they also get less bogo, probably they cant afford to buy one so often, that they should not get the next one for free,\n",
    "#the strcuture is that low income people get more informational and less value rewarindg coupons, but it seems not significant ()\n",
    "print(\"bogo high:\", starbucks_filtered.bogo[starbucks_filtered.income > 65405].sum())\n",
    "print(\"bogo low:\", starbucks_filtered.bogo[starbucks_filtered.income <= 65405].sum())\n",
    "print(\"discount high:\", starbucks_filtered.discount[starbucks_filtered.income > 65405].sum())\n",
    "print(\"discount low:\", starbucks_filtered.discount[starbucks_filtered.income <= 65405].sum())\n",
    "print(\"informational high:\", starbucks_filtered.informational[starbucks_filtered.income > 65405].sum())\n",
    "print(\"informational low:\", starbucks_filtered.informational[starbucks_filtered.income <= 65405].sum())\n",
    "#the mean strengthens the underlying structure from the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we still try to do a permutation test, labeling ppl in the data set by mean and median and lets see if this would be a valid startegy\n",
    "#making group_names (permutation mostly works on the mean, so lets see)\n",
    "starbucks_filtered[\"income_mean\"] = np.where(starbucks_filtered.income >= 65405, \"high\", \"low\")\n",
    "starbucks_filtered[\"income_median\"] = np.where(starbucks_filtered.income >= 59000, \"high\", \"low\")\n",
    "\n",
    "starbucks_bogo_high_mean = starbucks_filtered.bogo[starbucks_filtered.income_mean == \"high\"]\n",
    "starbucks_bogo_low_mean = starbucks_filtered.bogo[starbucks_filtered.income_mean == \"low\"]\n",
    "\n",
    "starbucks_bogo_high_median = starbucks_filtered.bogo[starbucks_filtered.income_median == \"high\"]\n",
    "starbucks_bogo_low_median = starbucks_filtered.bogo[starbucks_filtered.income_median == \"low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real exact permutatuion test would be too much because of all permutations, but we will use a randomization test, paired, to check if \n",
    "# an approximate delivers us an insight if both distributions of bogos area equal between different income structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    p_value = permutation_test(list(starbucks_bogo_high_mean), list(starbucks_bogo_low_mean),\n",
    "                               method='approximate',\n",
    "                               num_rounds=30000,\n",
    "                               seed=_)\n",
    "    print(pd.DataFrame([p_value]).round(5))\n",
    "#Since p-value < alpha 0.05, we can reject the null hypothesis that the two samples come from the same distribution.\n",
    "# thus the bogos are different between income in terms of mean, lets have a look at the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    p_value = permutation_test(list(starbucks_bogo_high_median), list(starbucks_bogo_low_median),\n",
    "                               method='approximate',\n",
    "                               num_rounds=30000,\n",
    "                               seed=_)\n",
    "    print(pd.DataFrame([p_value]).round(5))\n",
    "    \n",
    "#also different in terms of median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the magnitude in differences shows differences regardless of median and mean, we can be assured this feature may some impact in forecastin income\n",
    "# but we will see this from the permutation importance of a method also\n",
    "print(\"mean_differences\")\n",
    "print(\"****************\")\n",
    "print(\"bogo diff:\", starbucks_filtered.bogo[starbucks_filtered.income > 59000].sum() - starbucks_filtered.bogo[starbucks_filtered.income <= 59000].sum())\n",
    "print(\"discount diff:\", starbucks_filtered.discount[starbucks_filtered.income > 59000].sum() - starbucks_filtered.discount[starbucks_filtered.income <= 59000].sum())\n",
    "print(\"informational diff:\", starbucks_filtered.informational[starbucks_filtered.income > 59000].sum() - starbucks_filtered.informational[starbucks_filtered.income <= 59000].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"median_differences\")\n",
    "print(\"****************\")\n",
    "print(\"bogo diff:\", starbucks_filtered.bogo[starbucks_filtered.income > 65405].sum() - starbucks_filtered.bogo[starbucks_filtered.income <= 65405].sum())\n",
    "print(\"discount diff:\", starbucks_filtered.discount[starbucks_filtered.income > 65405].sum() - starbucks_filtered.discount[starbucks_filtered.income <= 65405].sum())\n",
    "print(\"informational diff:\", starbucks_filtered.informational[starbucks_filtered.income > 65405].sum() - starbucks_filtered.informational[starbucks_filtered.income <= 65405].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#are empty gender rows and missing income rows equal?\n",
    "any(starbucks[starbucks.income.isna()].index == starbucks[starbucks.gender==\"\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok then we only need one column to filter for both missing features and creating a missing and a full data frame\n",
    "starbucks_income_gender_missing = starbucks[starbucks.income.isna()]\n",
    "starbucks_income_gender_full = starbucks[starbucks.income.notna()]\n",
    "\n",
    "# getting the targets from the full data frame\n",
    "starbucks_income_full_y = starbucks_income_gender_full.income\n",
    "starbucks_gender_full_y = starbucks_income_gender_full.gender\n",
    "\n",
    "#dropping targets from the features\n",
    "starbucks_income_gender_full_x = starbucks_income_gender_full.drop([\"income\", \"gender\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelencoding for gender\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(starbucks_gender_full_y)\n",
    "transformed_gender = lbl.transform(starbucks_gender_full_y)\n",
    "print(lbl.classes_)\n",
    "print(transformed_gender)\n",
    "starbucks_gender_full_y = transformed_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_gender_full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_filtered\n",
    "\n",
    "#0, 1, 0 = Male\n",
    "#1, 0, 0 F\n",
    "#other is O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we need gender in the train set for Nan prediction?\n",
    "#no not because we dont need it, but because it doesnt work!\n",
    "#we cant use encoding for gender in train data since our test set also wont have these features for predict, \n",
    "#we cant use gender for prediction of income if the test set has NaNs in the gender in the same way as income, even if Nan means empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a simple prediction imputation for income, trees need no scaling doesnt matter if reg tree or class tree\n",
    "# we fit a model on the full data\n",
    "X_train, X_test, y_train, y_test = train_test_split(starbucks_income_gender_full_x, starbucks_income_full_y, random_state=0)\n",
    "\n",
    "steps = [('extra', ExtraTreesRegressor())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {\n",
    "    \"extra__max_depth\": [4, 8, 16, 24, 32],\n",
    "    \"extra__min_samples_split\": [2, 4, 6, 8, 10, 12, 16, 24, 32],\n",
    "    \"extra__min_samples_leaf\": [2, 4, 6, 8, 10, 12, 24, 32]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, params, cv = 5, n_iter=50, random_state=0, verbose=5, scoring=\"neg_mean_absolute_error\")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTreesRegressor Imputing income with best params solution\n",
    "extraReg = ExtraTreesRegressor(\n",
    "    min_samples_split=random_search.best_params_[\"extra__min_samples_split\"],\n",
    "    min_samples_leaf=random_search.best_params_[\"extra__min_samples_leaf\"], \n",
    "    max_depth=random_search.best_params_[\"extra__max_depth\"])\n",
    "\n",
    "extraReg.fit(X_train, y_train)\n",
    "\n",
    "# train_r2_score partial data\n",
    "train_r2 = r2_score(np.array(y_train).reshape(-1, 1), extraReg.predict(X_train))\n",
    "print(train_r2)\n",
    "\n",
    "#test r2_score partial_data\n",
    "test_r2 = r2_score(y_test, extraReg.predict(X_test))\n",
    "print(test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at our train r2 with full data (retrain on full data after tuning)\n",
    "extraReg.fit(starbucks_income_gender_full_x, starbucks_income_full_y)\n",
    "train_r2 = r2_score(starbucks_income_full_y, extraReg.predict(starbucks_income_gender_full_x))\n",
    "train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing_x = starbucks_income_gender_missing.drop([\"income\", \"gender\"], axis=1)\n",
    "starbucks_income_gender_missing.income = extraReg.predict(starbucks_income_gender_missing_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing\n",
    "# forecasting NaN worked for income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a simple prediction imputation for gender\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    starbucks_income_gender_full_x, \n",
    "    starbucks_gender_full_y, \n",
    "    random_state=0, \n",
    "    stratify=starbucks_gender_full_y\n",
    ")\n",
    "\n",
    "steps = [('extra', ExtraTreesClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {\n",
    "    \"extra__max_depth\": [4, 8, 16, 24, 32],\n",
    "    \"extra__min_samples_split\":[2, 4, 6, 8, 10, 12, 16, 24, 32],\n",
    "    \"extra__min_samples_leaf\":[2, 4, 6, 8, 10, 12, 24, 32]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, params, cv = 5, n_iter=50, random_state=0, verbose=5, scoring=\"accuracy\")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelBinarizer for gender\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lbl = LabelBinarizer()\n",
    "lbl.fit(starbucks_gender_full_y)\n",
    "transformed_gender = lbl.transform(starbucks_gender_full_y)\n",
    "print(lbl.classes_)\n",
    "print(transformed_gender)\n",
    "starbucks_gender_full_y = transformed_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_gender_full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_gender_full_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTreesClassifier Imputing gender with best params solution\n",
    "extraReg_class = ExtraTreesClassifier(\n",
    "    min_samples_split=random_search.best_params_[\"extra__min_samples_split\"],\n",
    "    min_samples_leaf=random_search.best_params_[\"extra__min_samples_leaf\"], \n",
    "    max_depth=random_search.best_params_[\"extra__max_depth\"])\n",
    "\n",
    "extraReg_class.fit(X_train, y_train)\n",
    "\n",
    "# train_r2_score partial data\n",
    "train_acc = accuracy_score(y_train, extraReg_class.predict(X_train))\n",
    "print(train_acc)\n",
    "\n",
    "#test r2_score partial_data\n",
    "test_acc = accuracy_score(y_test, extraReg_class.predict(X_test))\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain fit on full train data and then forecast\n",
    "extraReg_class.fit(starbucks_income_gender_full_x, starbucks_gender_full_y)\n",
    "#seems like an overfitted tree?\n",
    "train_accuracy = accuracy_score(starbucks_gender_full_y, extraReg_class.predict(starbucks_income_gender_full_x))\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no predict proba since we want to work directly with imputed labels\n",
    "starbucks_income_gender_missing.gender = extraReg_class.predict(starbucks_income_gender_missing_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing.gender.unique()\n",
    "#should ow be full with forecasted imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_full.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(starbucks_income_gender_missing.gender == 0).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing.gender = np.where(starbucks_income_gender_missing.gender == 0, \"M\", \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_income_gender_missing.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate persons with missing values with persons and real data\n",
    "starbucks_imputed_full = starbucks_income_gender_full.append(starbucks_income_gender_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous\n",
    "fig = px.histogram(starbucks_income_gender_full, x=\"gender\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now\n",
    "fig = px.histogram(starbucks_imputed_full, x=\"gender\")\n",
    "fig.show()\n",
    "#seems more distorted now, however, if we would have filled the most frequent we would have only male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(starbucks_imputed_full, x=\"income\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we look at the distributions with the imputed values again\n",
    "fig = px.histogram(starbucks_imputed_full, x=\"income\", color=starbucks_imputed_full.gender, marginal=\"violin\",\n",
    "                         hover_data=starbucks_imputed_full.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_imputed_full.age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_imputed_full.age = np.where(starbucks_imputed_full.age > 90, 0, starbucks_imputed_full.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok then we only need one column to filter for both missing features\n",
    "starbucks_age_missing = starbucks_imputed_full[starbucks_imputed_full.age == 0]\n",
    "starbucks_age_full = starbucks_imputed_full[starbucks_imputed_full.age != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_age_full_y = starbucks_age_full.age\n",
    "starbucks_age_full_x = starbucks_age_full.drop([\"age\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_age_full_x.gender = np.where(starbucks_age_full_x.gender==\"M\", 0, np.where(starbucks_age_full_x.gender==\"F\", 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a simple prediction imputation for age, since the values over 90 are bullshit\n",
    "X_train, X_test, y_train, y_test = train_test_split(starbucks_age_full_x, starbucks_age_full_y, random_state=0)\n",
    "\n",
    "\n",
    "steps = [('extra', ExtraTreesRegressor())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {\n",
    "    \"extra__max_depth\": [4, 8, 16, 24, 32],\n",
    "    \"extra__min_samples_split\":[2, 4, 6, 8, 10, 12, 16, 24, 32],\n",
    "    \"extra__min_samples_leaf\":[2, 4, 6, 8, 10, 12, 24, 32]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    params, \n",
    "    cv = 5, \n",
    "    n_iter=50, \n",
    "    random_state=0,\n",
    "    verbose=5, \n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTreesRegressor Imputing age with best params\n",
    "extraReg = ExtraTreesRegressor(\n",
    "    min_samples_split=random_search.best_params_[\"extra__min_samples_split\"],\n",
    "    min_samples_leaf=random_search.best_params_[\"extra__min_samples_leaf\"], \n",
    "    max_depth=random_search.best_params_[\"extra__max_depth\"])\n",
    "\n",
    "extraReg.fit(X_train, y_train)\n",
    "\n",
    "# train_r2_score partial data\n",
    "train_r2 = r2_score(np.array(y_train).reshape(-1, 1), extraReg.predict(X_train))\n",
    "print(train_r2)\n",
    "\n",
    "#test r2_score partial_data\n",
    "test_r2 = r2_score(y_test, extraReg.predict(X_test))\n",
    "print(test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at our full train r2\n",
    "extraReg.fit(starbucks_age_full_x, starbucks_age_full_y)\n",
    "train_r2 = r2_score(starbucks_age_full_y, extraReg.predict(starbucks_age_full_x))\n",
    "train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_age_missing_x = starbucks_age_missing.drop([\"age\"], axis=1)\n",
    "starbucks_age_missing_x.gender = np.where(starbucks_age_missing_x.gender==\"M\", 0, np.where(starbucks_age_missing_x.gender==\"F\", 1, 2))\n",
    "starbucks_age_missing_x\n",
    "#needs gender as number for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_age_missing\n",
    "# not the same amount as in the previous part , may be that it was only a value of 118 that was too high, but 90 seems also too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_age_missing.age = extraReg.predict(starbucks_age_missing_x)\n",
    "starbucks_imputed_full_v2 = starbucks_age_full.append(starbucks_age_missing)\n",
    "starbucks_imputed_full_v2.age = round(starbucks_imputed_full_v2.age, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_imputed_full_v2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_imputed_full_v2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks_imputed_full_v2.to_csv(\"./starbucks_data/starbucks_imputed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
